import { Worker } from "bullmq";
import { redisConnection } from "../config/redis.js";
import AWS from "aws-sdk";
import fs from "fs";
import dotenv from "dotenv";
import path from "path";
import { PrismaClient } from "@prisma/client";
import { fileURLToPath } from "url";
import AdmZip from "adm-zip";
import { processLogFile } from "../parsers/logParser.js";

dotenv.config();
const prisma = new PrismaClient();

const s3 = new AWS.S3({
  accessKeyId: process.env.AWS_ACCESS_KEY_ID,
  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
  region: "ap-south-1",
});

// ‚úÖ Define __dirname manually for ES Modules
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/**
 * Saves structured log data to Redis
 * @param {String} userId - User ID
 * @param {String} logId - Unique log ID
 * @param {Object} fightsData - Structured fights object
 */
async function saveToRedis(userId, logId, fightsData) {
  try {
    const key = `log:${userId}:${logId}`;
    await redisConnection.setex(key, 3600, JSON.stringify(fightsData)); // Expires in 1 hour
    await redisConnection.set(`log:${userId}:latest`, logId);
    console.log(`‚úÖ Log saved in Redis: ${key}`);
  } catch (error) {
    console.error("‚ùå Redis save error:", error);
  }
}

const logWorker = new Worker(
  "log-processing-queue",
  async (job) => {
    try {
      const { logId, s3FilePath } = job.data;
      console.log(`üöÄ Processing log (ID: ${logId})...`);
      console.log(`üîç Fetching file from S3: ${s3FilePath}`);
      const userId = "12345";

      const urlObj = new URL(s3FilePath);
      const s3ObjectKey = urlObj.pathname.substring(1);

      // ‚úÖ Fetch the log file from S3
      //   const s3ObjectKey = s3FilePath.split(".com/")[1]; // Extract object key
      console.log(`üìÇ Extracted S3 Object Key: ${s3ObjectKey}`);
      const zipFile = await s3
        .getObject({ Bucket: process.env.AWS_BUCKET_NAME, Key: s3ObjectKey })
        .promise();

      if (!zipFile.Body) {
        throw new Error("Log file is empty or inaccessible");
      }

      console.log(`‚úÖ Successfully fetched file from S3`);

      // ‚úÖ Ensure the /tmp/ directory exists (Cross-platform fix)
      const tempDir = path.join(__dirname, "..", "tmp"); // Windows & Linux compatible
      if (!fs.existsSync(tempDir)) {
        fs.mkdirSync(tempDir, { recursive: true });
      }

      // ‚úÖ Write file to tmp directory
      const tempZipPath = path.join(tempDir, `log-${logId}.zip`);
      fs.writeFileSync(tempZipPath, zipFile.Body);

      console.log(`üìÑ .zip file saved locally: ${tempZipPath}`);

      // ‚úÖ Extract .zip file
      const extractPath = path.join(tempDir, `log-${logId}`);
      if (!fs.existsSync(extractPath)) {
        fs.mkdirSync(extractPath);
      }

      const zip = new AdmZip(tempZipPath);
      zip.extractAllTo(extractPath, true);

      console.log(`üìÇ Extracted files to: ${extractPath}`);

      // ‚úÖ Iterate over extracted files
      const extractedFiles = fs.readdirSync(extractPath);
      console.log(`üìÉ Found ${extractedFiles.length} log files in .zip`);

      for (const fileName of extractedFiles) {
        const filePath = path.join(extractPath, fileName);

        // ‚úÖ Ensure it's a text file before processing
        if (fileName.endsWith(".txt")) {
          console.log(`üìë Processing extracted file: ${fileName}`);

          // ‚úÖ Parse the log file and structure encounters
          const structuredFights = await processLogFile(filePath, logId);

          console.log(`‚úÖ Log parsing completed for log ID: ${logId}`);

          if (structuredFights) {
            console.log(`üîπ Storing log in Redis for quick access...`);

            console.log(logId);
            await saveToRedis(userId, logId, structuredFights);
          }

          // ‚úÖ Save structured fights to PostgreSQL (Optional, add DB integration here)
          // await prisma.logs.update({
          //   where: { logId },
          //   data: {
          //     processingStatus: "completed",
          //     structuredDataPath: `logs/json/log-${logId}.json`, // Store structured log path
          //   },
          // });

          await prisma.logs.update({
            where: { logId },
            data: {
              processingStatus: "completed",
              structuredDataPath: `logs/json/log-${logId}.json`, // Store structured log path
              processedAt: new Date(), // Timestamp for completion
            },
          });
        } else {
          throw new Error(
            `‚ùå Invalid file detected: ${fileName}. Only .txt or .log files are allowed.`
          );
        }
      }

      //update db that the log has been parsed
      await prisma.logs.update({
        where: { logId },
        data: { processingStatus: "completed" },
      });

      console.log(`‚úÖ Processing completed for log ID: ${logId}`);

      // ‚úÖ Cleanup: Delete extracted files and zip
      fs.unlinkSync(tempZipPath);
      fs.rmSync(extractPath, { recursive: true, force: true });

      console.log(`üóëÔ∏è Cleaned up temp files.`);
    } catch (error) {
      console.error("‚ùå Error processing log:", error.message);

      await prisma.logs.update({
        where: { logId: job.data.logId },
        data: { processingStatus: "failed" },
      });
    }
  },
  { connection: redisConnection }
);

console.log("üë∑ Log processing worker started...");

export default logWorker;
